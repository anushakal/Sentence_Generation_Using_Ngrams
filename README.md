# Sentence_Generation_Using_Ngrams - Homework assignment
## Overview
This repository contains a Python implementation of a Language Model for short story generation using Natural Language Processing (NLP) techniques. The language model is trained on fanfiction archives, and it can generate sentences based on Unigram and Bigram approaches. The implementation includes features like Laplace smoothing and perplexity calculation.

## Features
- **Unigram and Bigram Approaches**: The language model supports both unigram and bigram approaches for sentence generation.
- **Laplace Smoothing**: Optional Laplace smoothing can be applied to handle unseen n-grams during sentence scoring.
- **Perplexity Calculation**: The repository includes a function to calculate perplexity for a given test sequence.
- **Manual Assessment**: Sentences are generated and scored manually using provided test sets to evaluate the model's performance.

The implementation is written from scratch without relying on external libraries. No pre-built NLP libraries or frameworks are used.
